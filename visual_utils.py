import torch 
import transformers
from transformers import TrainerCallback
from torch.utils.data import Dataset
from peft import LoraConfig, get_peft_model, prepare_model_for_int8_training, PeftModel
import wandb
import sys
wandb.init(mode="disabled")
sys.path.append('..')
import utils
from dataclasses import dataclass, field
from typing import Dict, Optional, Sequence
from transformers.models.llama.modeling_llama import LlamaAttention,LlamaMLP
from transformers.models.opt.modeling_opt import OPTAttention
import numpy as np 
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
# // Set access token (NB: Keep this private!)
access_token = next(open('huggingface_token.txt')).strip()

def extract_feature(model, alignment_dataloader ):
    hidden_embedding_all = []
    # Your custom logic to accumulate embeddings and labels
    def get_leaf_modules_with_grad(module):
        module_list= []
        index= 0
        for name, module in module.named_modules():
            if isinstance(module,LlamaAttention) or isinstance(module, OPTAttention):
                module_list+= [module]
        # # print(module_list)
        return module_list
    
    def track_embedding_hook(original_embedding):
        def hook(module, input, output):
            mean_output = torch.mean(output[0].detach().to("cpu"), dim=1)
            # print(mean_output.shape)
            original_embedding.append(mean_output.view(-1))
            torch.cuda.empty_cache()
            return output
        return hook


    def apply_track_drift_hooks_recursive(module, hook_fn, hooks):
        hook = module.register_forward_hook(hook_fn)
        hooks.append(hook)
        
        
    for index, batch in enumerate(alignment_dataloader):
        original_embedding = []
        hooks = []
        leaf_modules_with_grad = get_leaf_modules_with_grad(model)
        for layer in leaf_modules_with_grad:
            apply_track_drift_hooks_recursive(layer, track_embedding_hook(original_embedding), hooks)
        inputs = batch["input_ids"]
        # here need to track hidden embedding 
        model(inputs) 
        original_embedding = torch.cat(original_embedding)
        hidden_embedding_all+=[original_embedding]
    # hidden_embedding_all = torch.cat(hidden_embedding_all)
    return hidden_embedding_all
    

def visual_test_tsne():
    embedded_features = torch.tensor(
[
[9.046016693115234, 3.8881959915161133],
[14.562360763549805, 3.3653857707977295],
[15.388165473937988, -0.6391612887382507],
[13.738603591918945, -2.039428472518921],
[1.0381271839141846, -0.42743656039237976],
[11.639860153198242, -1.274300456047058],
[15.792901039123535, 1.7323001623153687],
[9.988446235656738, -2.281947612762451],
[7.217248439788818, 0.9741223454475403],
[9.825958251953125, 2.0714402198791504],
[9.998604774475098, -0.7157968282699585],
[11.232163429260254, 1.2588051557540894],
[5.563322067260742, 4.7798285484313965],
[-12.54858112335205, -1.2081016302108765],
[7.754011154174805, -2.6545066833496094],
[9.219996452331543, 0.5942211747169495],
[4.8703436851501465, -0.4863671064376831],
[11.80266284942627, 2.603073835372925],
[9.332218170166016, 5.015165328979492],
[4.914269924163818, 1.8182538747787476],
[7.650031089782715, -1.114987850189209],
[7.524417877197266, 2.904087543487549],
[11.964081764221191, 5.247740745544434],
[11.880133628845215, -3.8033320903778076],
[9.273002624511719, -4.651408672332764],
[10.910210609436035, 0.4709520936012268],
[12.476095199584961, 0.17755316197872162],
[1.6682604551315308, 1.4779852628707886],
[6.057619571685791, 0.47452419996261597],
[13.685726165771484, 0.8910357356071472],
[-2.3933305740356445, 2.5750958919525146],
[-1.1212544441223145, 0.14866575598716736],
[-6.879914283752441, -1.6352488994598389],
[-6.303111553192139, 9.48876953125],
[1.5380440950393677, 4.1166911125183105],
[-10.354715347290039, 3.669069528579712],
[-7.5629801750183105, 4.771252632141113],
[-4.923620223999023, 3.6592397689819336],
[-8.656030654907227, 5.934563159942627],
[-8.299492835998535, 3.535447120666504],
[-0.8683891892433167, 5.479013919830322],
[-12.698598861694336, 4.079974174499512],
[-11.560144424438477, 3.4250688552856445],
[-9.960702896118164, -1.1284431219100952],
[-6.540081977844238, 3.3397085666656494],
[-9.832466125488281, 1.4270931482315063],
[-10.631693840026855, 5.481101989746094],
[-9.135831832885742, 2.6865181922912598],
[-6.09548282623291, -0.09451281279325485],
[-3.8759403228759766, 0.6792851090431213],
[-8.6096830368042, 0.9768425822257996],
[-10.26636028289795, 2.4485931396484375],
[-6.083287239074707, 1.8454400300979614],
[-5.350741863250732, 6.9299798011779785],
[-12.423105239868164, 1.480351209640503],
[1.1345876455307007, 7.476734161376953],
[-10.688497543334961, 0.6321464776992798],
[-7.038163185119629, 8.447568893432617],
[-7.8977580070495605, 2.248661994934082],
[-9.083236694335938, 4.037975788116455],
[10.054902076721191, 3.729281187057495],
[14.528441429138184, 3.3117804527282715],
[15.32597827911377, -0.19061337411403656],
[13.759795188903809, -1.9305821657180786],
[1.2566947937011719, -0.2968384921550751],
[11.843503952026367, -0.8028354644775391],
[15.97326374053955, 1.8161981105804443],
[9.988348960876465, -2.2659080028533936],
[6.989546775817871, 1.0743920803070068],
[10.449774742126465, 2.1961257457733154],
[10.233773231506348, -0.6642100214958191],
[12.18758773803711, 1.3618273735046387],
[5.722629547119141, 4.858709812164307],
[-12.568075180053711, -1.2386385202407837],
[7.315535545349121, -3.2122011184692383],
[8.872286796569824, 0.6581404805183411],
[4.899717807769775, -0.698175847530365],
[12.022418022155762, 2.5755467414855957],
[9.32172966003418, 5.177599906921387],
[5.256941318511963, 1.6604623794555664],
[7.913427352905273, -1.0386627912521362],
[7.311973571777344, 2.9468283653259277],
[12.166728973388672, 4.850996494293213],
[11.836767196655273, -3.8283770084381104],
[9.198234558105469, -4.966646194458008],
[11.438434600830078, 0.46447405219078064],
[12.431391716003418, 0.585652232170105],
[1.8389651775360107, 1.4659334421157837],
[6.460119247436523, 0.08318374305963516],
[14.013060569763184, 1.330065131187439],
[-2.535796880722046, 2.62617564201355],
[3.957780122756958, -3.211055278778076],
[-7.108263969421387, -1.423854112625122],
[-5.303452014923096, 5.099143981933594],
[1.6105003356933594, 4.104734897613525],
[-2.717052936553955, 7.549386978149414],
[-6.943384170532227, 5.131891250610352],
[-4.942799091339111, 3.9254846572875977],
[-8.680316925048828, 5.815136909484863],
[-8.014620780944824, 3.34922456741333],
[-0.7986365556716919, 5.861602783203125],
[-1.6101455688476562, 7.599100589752197],
[-3.3653206825256348, 7.113349914550781],
[-9.957963943481445, -1.3014661073684692],
[-6.5718770027160645, 3.279222011566162],
[-1.3635399341583252, 4.607640743255615],
[-10.215834617614746, 6.513307571411133],
[-9.08784294128418, 2.697657585144043],
[-7.186556816101074, 0.342037558555603],
[-3.8846435546875, 0.7929811477661133],
[-8.451435089111328, 0.2642304003238678],
[-10.277530670166016, 2.6463210582733154],
[-6.129481315612793, 1.977242350578308],
[-3.9143733978271484, 7.593785285949707],
[-12.214892387390137, 1.5604979991912842],
[1.0582088232040405, 7.350036144256592],
[-3.899672031402588, 6.242936134338379],
[-6.930965423583984, 8.348464012145996],
[5.501779079437256, -2.802262544631958],
[-1.582610011100769, 6.520677089691162],
]
)
    embedded_features2=(
    [
[4.430748462677002, 3.480051279067993],
[7.609931945800781, 7.77993106842041],
[5.201371669769287, 8.470314025878906],
[6.550191402435303, 7.91821813583374],
[-0.6245110034942627, 2.0697546005249023],
[4.578084945678711, 5.530022621154785],
[8.300976753234863, 6.75171422958374],
[2.8789305686950684, 5.7069315910339355],
[3.8572404384613037, 2.1442134380340576],
[3.8721232414245605, 5.670151710510254],
[5.634113788604736, 5.234874725341797],
[5.509939670562744, 6.048546314239502],
[2.3523576259613037, 2.0383098125457764],
[-1.1479626893997192, -0.028176873922348022],
[3.788649082183838, 6.516289234161377],
[4.393967151641846, 6.1521992683410645],
[4.7092790603637695, 1.1101293563842773],
[4.9839959144592285, 7.119512557983398],
[5.362376689910889, 4.013986587524414],
[2.748239278793335, 0.2760220766067505],
[2.432769536972046, 2.8010499477386475],
[5.831839561462402, 7.4832024574279785],
[5.582369804382324, 2.5848300457000732],
[7.43481969833374, 4.051338195800781],
[3.1894917488098145, 7.398988246917725],
[5.394584655761719, 6.100302219390869],
[6.001084804534912, 6.533693313598633],
[0.4683864414691925, 1.7232446670532227],
[3.523280620574951, 1.7167779207229614],
[6.716439723968506, 6.523588180541992],
[1.2453439235687256, -5.850710868835449],
[-1.7054933309555054, 1.3784657716751099],
[-1.678069829940796, -2.7439043521881104],
[-10.424654006958008, -3.321253538131714],
[0.10843552649021149, -2.4906980991363525],
[-7.759681701660156, -5.3589019775390625],
[-5.610403060913086, -5.529313087463379],
[-8.740340232849121, -2.1710517406463623],
[-3.466562032699585, -3.657742738723755],
[-3.6120479106903076, -4.924632549285889],
[-1.410955786705017, -5.443458557128906],
[-7.163392066955566, -1.1511378288269043],
[-7.06697940826416, -3.015939950942993],
[-5.175905704498291, -1.3134934902191162],
[-3.6229965686798096, -7.7732343673706055],
[-6.519857406616211, -6.186451435089111],
[-7.519000053405762, -6.951457500457764],
[-5.914412975311279, -4.326770782470703],
[-2.91678524017334, -2.04543137550354],
[-5.886613368988037, -9.428125381469727],
[-4.93688440322876, -4.457871913909912],
[-6.6079864501953125, -4.790950298309326],
[-5.403144836425781, -7.179194450378418],
[-6.121304988861084, 1.5699254274368286],
[-5.936529159545898, -2.5615768432617188],
[-3.614267110824585, -2.1725032329559326],
[-4.892968654632568, -2.8356361389160156],
[-10.047253608703613, -4.693547248840332],
[-7.951555252075195, -3.850830316543579],
[-4.423839569091797, -5.782402992248535],
[4.215395927429199, 3.2111759185791016],
[7.7700886726379395, 1.4449255466461182],
[1.0642646551132202, 4.24886417388916],
[7.283614635467529, 2.348874092102051],
[6.770014762878418, 0.4557048976421356],
[3.2629036903381348, 3.7506394386291504],
[8.964482307434082, 6.239258766174316],
[1.8084179162979126, 5.227137088775635],
[3.900585174560547, 1.1059832572937012],
[0.9742677211761475, 3.6634249687194824],
[5.9271345138549805, 4.673486232757568],
[6.773677349090576, 4.939159393310547],
[2.399557113647461, 4.30380392074585],
[-0.4147442877292633, 0.5378258228302002],
[8.865830421447754, 3.5260584354400635],
[3.151360273361206, 4.459110260009766],
[5.1494927406311035, 1.1611440181732178],
[4.729094505310059, 7.149033546447754],
[5.783745288848877, 3.7074193954467773],
[2.7350170612335205, 0.16703543066978455],
[2.895029067993164, 2.9950695037841797],
[-3.3604583740234375, -0.32690125703811646],
[6.242156982421875, 2.480600357055664],
[7.108899116516113, 3.264450788497925],
[2.0011017322540283, 7.494682788848877],
[4.577198028564453, 4.494329452514648],
[7.323079586029053, 6.376257419586182],
[0.669110894203186, 1.7396632432937622],
[5.937636375427246, 1.2948029041290283],
[7.216236114501953, 5.548685073852539],
[1.2341132164001465, -5.842806816101074],
[-0.43950873613357544, -3.946784734725952],
[-1.8195537328720093, -2.7174715995788574],
[-10.263181686401367, -3.2418181896209717],
[7.722372055053711, 0.23766979575157166],
[-7.795729637145996, -5.236489295959473],
[-5.613412380218506, -5.456090450286865],
[-8.7072172164917, -2.1899051666259766],
[-3.520946979522705, -3.7758092880249023],
[-3.0464277267456055, -4.978016376495361],
[-1.594168782234192, -5.394240856170654],
[-7.086797714233398, -1.3971949815750122],
[-6.803648471832275, -3.335268020629883],
[-5.142834663391113, -1.200358510017395],
[-2.946660280227661, -8.223697662353516],
[-2.6369521617889404, -6.356489181518555],
[-7.6828718185424805, -7.3956170082092285],
[-5.8415422439575195, -4.336129665374756],
[-1.7528730630874634, -3.490919351577759],
[-5.8752641677856445, -9.45623779296875],
[-4.884698390960693, -4.236012935638428],
[-6.775960445404053, -4.826771259307861],
[-5.417239189147949, -7.154965877532959],
[-6.12803316116333, 1.568689227104187],
[-5.84510612487793, -3.2698163986206055],
[9.441269874572754, 1.7398054599761963],
[-4.819936752319336, -3.025611162185669],
[-9.655557632446289, -5.224545001983643],
[-7.8079376220703125, -3.879196882247925],
[-4.24588680267334, -5.879980087280273],
]
    )
    
   
    # print(len(embedded_features))
    # print(embedded_features)
    # print(embedded_features.shape)
    
    import matplotlib.pyplot as plt
    
    
    colors = ['red', 'blue', 'green', 'purple', 'orange']
    # Add jitter to the points
    jitter_strength = 0.01  # Adjust the strength of the jitter
    np.random.seed(0)
    jitter = np.random.normal(scale=jitter_strength, size=embedded_features.shape)
    jittered_features = embedded_features +jitter
    jittered_features2 = embedded_features2 +jitter
    
    
    
    # Create a figure with two subplots
    fig, axes = plt.subplots(1, 2, figsize=(12, 6))

    # First subplot
    axes[0].scatter(jittered_features[:30, 0], jittered_features[:30, 1], c=colors[0], label="Before prune (gsm8k)", alpha=0.5)
    axes[0].scatter(jittered_features[60:90, 0], jittered_features[60:90, 1], c=colors[2], label="After prune (gsm8k)", alpha=0.5)
    axes[0].scatter(jittered_features[30:60, 0], jittered_features[30:60, 1], c=colors[1], label="Before prune (harmful data)", alpha=0.5)
    axes[0].scatter(jittered_features[90:120, 0], jittered_features[90:120, 1], c=colors[3], label="After prune (harmful data)", alpha=0.5)
    axes[0].legend(fontsize=12)
    axes[0].set_title('Before prune vs. After prune (Antidote)', fontsize=15)
    axes[0].set_xticks([])
    axes[0].set_yticks([])

    # Second subplot (You can modify this with different data or visualization)
    # Second subplot (New Data)
    axes[1].scatter(jittered_features2[:30, 0], jittered_features2[:30, 1], c=colors[0], label="Before prune (gsm8k)", alpha=0.5)
    axes[1].scatter(jittered_features2[60:90, 0], jittered_features2[60:90, 1], c=colors[2], label="After prune (gsm8k)", alpha=0.5)
    axes[1].scatter(jittered_features2[30:60, 0], jittered_features2[30:60, 1], c=colors[1], label="Before prune (harmful data)", alpha=0.5)
    axes[1].scatter(jittered_features2[90:120, 0], jittered_features2[90:120, 1], c=colors[3], label="After prune (harmful data)", alpha=0.5)
    axes[1].legend(fontsize=12)
    axes[1].set_title('Before prune vs. After prune (Random Pruning)', fontsize=15)
    axes[1].set_xticks([])
    axes[1].set_yticks([])
    # plt.colorbar()
    plt.tight_layout()
    plt.savefig("tsne", dpi=600)
    
visual_test_tsne()